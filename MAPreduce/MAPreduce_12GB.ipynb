{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ciiTbEokQlB"
      },
      "outputs": [],
      "source": [
        "# Install Java, Spark, and PySpark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -xvzf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def create_spark_session():\n",
        "    try:\n",
        "        spark = SparkSession.builder \\\n",
        "            .appName(\"WordCount\") \\\n",
        "            .config(\"spark.executor.memory\", \"2g\") \\\n",
        "            .config(\"spark.driver.memory\", \"2g\") \\\n",
        "            .config(\"spark.executor.cores\", \"2\") \\\n",
        "            .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
        "            .config(\"spark.local.dir\", \"/content/spark-temp\") \\\n",
        "            .getOrCreate()\n",
        "        print(\"Spark session created successfully.\")\n",
        "        return spark\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating Spark session: {e}\")\n",
        "        return None\n",
        "\n",
        "spark = create_spark_session()"
      ],
      "metadata": {
        "id": "Hop_Rm0pkVrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc108b8-7159-490e-f639-c9c289e1d974"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7aK52DYoebm",
        "outputId": "491208fc-7bab-4b20-b48f-4380b47c5a49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print RAM and CPU usage\n",
        "import psutil\n",
        "def print_usage():\n",
        "    mem = psutil.virtual_memory()\n",
        "    total_mem = mem.total / (1024**3)  # Convert from bytes to GB\n",
        "    available_mem = mem.available / (1024**3)  # Convert from bytes to GB\n",
        "    used_mem = total_mem - available_mem\n",
        "\n",
        "    # Get CPU usage\n",
        "    cpu_usage = psutil.cpu_percent(interval=1)\n",
        "\n",
        "    print(f\"Total RAM: {total_mem:.2f} GB\")\n",
        "    print(f\"Used RAM: {used_mem:.2f} GB\")\n",
        "    print(f\"Available RAM: {available_mem:.2f} GB\")\n",
        "    print(f\"CPU Usage: {cpu_usage:.2f}%\")"
      ],
      "metadata": {
        "id": "bjrs5QXEpX6M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/DATASET/mergedfiles12GB.txt'\n",
        "\n",
        "import time\n",
        "# Preprocessing Timer\n",
        "preprocessing_start = time.time()\n",
        "\n",
        "# Read the text file\n",
        "df = spark.read.text(file_path)\n",
        "\n",
        "# Filter to include only alphabetic characters, ignore spaces, commas, and dots, and convert to lowercase\n",
        "import re\n",
        "filtered_rdd = df.rdd.map(lambda row: (re.sub(r'[^a-zA-Z]', ' ', row.value).lower(),))\n",
        "\n",
        "# Define schema\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "schema = StructType([StructField(\"value\", StringType(), True)])\n",
        "\n",
        "# Convert filtered RDD back to DataFrame\n",
        "filtered_df = spark.createDataFrame(filtered_rdd, schema)\n",
        "\n",
        "filtered_df.show(50)\n",
        "\n",
        "# Cache the DataFrame for faster access\n",
        "filtered_df.cache()\n",
        "\n",
        "preprocessing_end = time.time()\n",
        "preprocessing_time = preprocessing_end - preprocessing_start\n",
        "print(f\"Preprocessing Time: {preprocessing_time:.2f} seconds\")\n",
        "\n",
        "# Word Count Timer\n",
        "word_count_start = time.time()\n",
        "\n",
        "# Perform word count using map-reduce\n",
        "words = filtered_df.rdd.flatMap(lambda line: line.value.split())\n",
        "word_counts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "word_count_end = time.time()\n",
        "word_count_time = word_count_end - word_count_start\n",
        "print(f\"Word Count Time: {word_count_time:.2f} seconds\")\n",
        "\n",
        "# Sorting Timer\n",
        "sorting_start = time.time()\n",
        "\n",
        "# Convert to DataFrame and sort by word count\n",
        "word_counts_df = word_counts.toDF([\"word\", \"count\"])\n",
        "sorted_word_counts_df = word_counts_df.orderBy(\"count\", ascending=False)\n",
        "\n",
        "sorting_end = time.time()\n",
        "sorting_time = sorting_end - sorting_start\n",
        "print(f\"Sorting Time: {sorting_time:.2f} seconds\")\n",
        "\n",
        "# Show the sorted word counts\n",
        "sorted_word_counts_df.show(50)\n",
        "\n",
        "print_usage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN3LIZWRpZ7t",
        "outputId": "2ad3acb3-23b9-42f3-a463-29066167cf0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|a rebel statement...|\n",
            "|authorities last ...|\n",
            "|at the first pan ...|\n",
            "|mr  neigum  poker...|\n",
            "|this  combined wi...|\n",
            "|she told the post...|\n",
            "|according to a st...|\n",
            "|preston tisch    ...|\n",
            "| we re dealing wi...|\n",
            "|asked if he might...|\n",
            "|he said muscovite...|\n",
            "|changes to the va...|\n",
            "| he came up to me...|\n",
            "|the government tr...|\n",
            "|but the official ...|\n",
            "| my husband says ...|\n",
            "|we look forward t...|\n",
            "|but other major b...|\n",
            "|so he joined hyat...|\n",
            "|de klerk said wed...|\n",
            "| the results are ...|\n",
            "|mr  hoover expect...|\n",
            "|the entree  like ...|\n",
            "|under the first c...|\n",
            "|in store s presid...|\n",
            "|quaker oats co  t...|\n",
            "|can we never see ...|\n",
            "|in addition  unio...|\n",
            "|while the results...|\n",
            "| the item veto is...|\n",
            "| this isn t a hos...|\n",
            "|in the long term ...|\n",
            "|some analysts bel...|\n",
            "|the yield on    y...|\n",
            "|the kit has an ad...|\n",
            "|last year  the fd...|\n",
            "|that would be qui...|\n",
            "|no children in th...|\n",
            "|as the first wine...|\n",
            "|the sterling valu...|\n",
            "|they have been ra...|\n",
            "| at the beginning...|\n",
            "| my gut reaction ...|\n",
            "|stock prices fell...|\n",
            "|in allendale coun...|\n",
            "|a study today con...|\n",
            "|and germans in bo...|\n",
            "|disney world in f...|\n",
            "|those opinions ar...|\n",
            "|the two firms lat...|\n",
            "+--------------------+\n",
            "only showing top 50 rows\n",
            "\n",
            "Preprocessing Time: 14.64 seconds\n",
            "Word Count Time: 2092.47 seconds\n",
            "Sorting Time: 2962.38 seconds\n",
            "+-------+---------+\n",
            "|   word|    count|\n",
            "+-------+---------+\n",
            "|    the|131738016|\n",
            "|     of| 57320256|\n",
            "|     to| 54556800|\n",
            "|      a| 49250880|\n",
            "|     in| 45635040|\n",
            "|    and| 43188768|\n",
            "|      s| 25353408|\n",
            "|   said| 20728800|\n",
            "|    for| 20662272|\n",
            "|   that| 19800288|\n",
            "|     is| 16871616|\n",
            "|     on| 15052608|\n",
            "|     it| 14010624|\n",
            "|    was| 13663008|\n",
            "|     he| 12730176|\n",
            "|   with| 11778624|\n",
            "|     by| 11769024|\n",
            "|     at| 11295360|\n",
            "|     as| 10842144|\n",
            "|   from| 10323072|\n",
            "|     be|  9849888|\n",
            "|    has|  8725632|\n",
            "|    but|  8656224|\n",
            "|   have|  8517408|\n",
            "|    are|  8484480|\n",
            "|     an|  8181408|\n",
            "|   will|  7025760|\n",
            "|    its|  6820416|\n",
            "|    his|  6745152|\n",
            "|   were|  6537024|\n",
            "|   they|  6506112|\n",
            "|   year|  6228576|\n",
            "|    not|  5952384|\n",
            "|  would|  5718912|\n",
            "|   this|  5638752|\n",
            "|     mr|  5351808|\n",
            "|    had|  5346240|\n",
            "|      t|  5336928|\n",
            "|  about|  5315904|\n",
            "|    new|  5229984|\n",
            "|million|  5087904|\n",
            "|    who|  5056896|\n",
            "|  which|  5031744|\n",
            "|   been|  5022048|\n",
            "|   more|  4888896|\n",
            "|  their|  4828992|\n",
            "|     or|  4662432|\n",
            "|    one|  4512768|\n",
            "|      i|  4262400|\n",
            "|     we|  4125600|\n",
            "+-------+---------+\n",
            "only showing top 50 rows\n",
            "\n",
            "Total RAM: 12.67 GB\n",
            "Used RAM: 3.62 GB\n",
            "Available RAM: 9.06 GB\n",
            "CPU Usage: 13.60%\n",
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|a rebel statement...|\n",
            "|authorities last ...|\n",
            "|at the first pan ...|\n",
            "|mr  neigum  poker...|\n",
            "|this  combined wi...|\n",
            "|she told the post...|\n",
            "|according to a st...|\n",
            "|preston tisch    ...|\n",
            "| we re dealing wi...|\n",
            "|asked if he might...|\n",
            "|he said muscovite...|\n",
            "|changes to the va...|\n",
            "| he came up to me...|\n",
            "|the government tr...|\n",
            "|but the official ...|\n",
            "| my husband says ...|\n",
            "|we look forward t...|\n",
            "|but other major b...|\n",
            "|so he joined hyat...|\n",
            "|de klerk said wed...|\n",
            "| the results are ...|\n",
            "|mr  hoover expect...|\n",
            "|the entree  like ...|\n",
            "|under the first c...|\n",
            "|in store s presid...|\n",
            "|quaker oats co  t...|\n",
            "|can we never see ...|\n",
            "|in addition  unio...|\n",
            "|while the results...|\n",
            "| the item veto is...|\n",
            "| this isn t a hos...|\n",
            "|in the long term ...|\n",
            "|some analysts bel...|\n",
            "|the yield on    y...|\n",
            "|the kit has an ad...|\n",
            "|last year  the fd...|\n",
            "|that would be qui...|\n",
            "|no children in th...|\n",
            "|as the first wine...|\n",
            "|the sterling valu...|\n",
            "|they have been ra...|\n",
            "| at the beginning...|\n",
            "| my gut reaction ...|\n",
            "|stock prices fell...|\n",
            "|in allendale coun...|\n",
            "|a study today con...|\n",
            "|and germans in bo...|\n",
            "|disney world in f...|\n",
            "|those opinions ar...|\n",
            "|the two firms lat...|\n",
            "+--------------------+\n",
            "only showing top 50 rows\n",
            "\n",
            "Preprocessing Time: 0.66 seconds\n"
          ]
        }
      ]
    }
  ]
}